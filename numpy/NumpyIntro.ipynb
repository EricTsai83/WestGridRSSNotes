{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "[Numpy](https://www.numpy.org/) is the foundation of most of what you will do with scientific python. Modules like [scipy](https://www.scipy.org/) and [pandas](https://pandas.pydata.org/) are built on top of numpy, and it is the linga franca for most numerical work in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are first introduced to python, one of the big selling points is that it isn't statically typed. You can do things like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a = 'apple'\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you don't get complaints from python about a being an integer. This is a _big_ advantage for python, and it works with collections as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = [1, 3., 'Ian', [range(3)], {'not': 'a good idea'}]\n",
    "myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists in python are about as general as they could be. This is very flexible and it lets you do some fancy things in Python, but it has a price. The Python interpreter can't make any assumptions about what will come next in a list; everything has to be treated as a generic object. Python does a good job of hiding the complexity of doing this, but as the lists get longer and more complex the overhead gets larger, and eventually perfomance becomes unacceptable.\n",
    "\n",
    "One solution to this is to use a statically typed (like C). There the burden of figuring out object types is left to the programmer, and the compiler can be much more efficient operating on them. A good example would be an array of `double`s. In memory, these will be allocated contiguously so when you need to jump to the 1402th double, you can do it with very simple arithmetic. Python has a much harder time because the memory allocated for your list could be a horrible mixture of all the different things you stuffed in there. \n",
    "\n",
    "Numpy attempts let you keep the advantages of Python without sacraficing the speed of static typing by adding the concept of homogenous collections to python, called `ndarray`s. The `ndarray` is the foundational concept in numpy, it is an array object which represents a multidimensional, homogeneous array of fixed-size items and Most commonly these items will be numbers.\n",
    "\n",
    "```\n",
    "%%timeit\n",
    "for i in range(1000000):\n",
    "    i*i\n",
    "```\n",
    "```\n",
    "%timeit np.arange(1000000)**2\n",
    "```\n",
    "\n",
    "_Incidently, if you dig deep enough in some of the numpy/scipy code you will find that the actual instructions you are executing were compiled from fortran and C. In general you can pass things quite easily between existing libraries and python, but fortran and C use different storage orders for multi-dimensional arrays so you have to be a little bit careful_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a` has the following attributes,\n",
    "\n",
    "  * **ndim**: The number of dimensions\n",
    "  * **shape**: A tuple giving the sizes of the dimensions\n",
    "  * **size**: The total number of elements (product of the shape items)\n",
    "  * **dtype**: The data type, int64, float64, complex128 etc.\n",
    "  * **itemsize**: The size of individual elements in memory\n",
    "  * **nbytes**: The total memory occupied by the ndarray\n",
    "  \n",
    "By knowing these attributes, numpy can use some of the same tricks that statically typed languges use because the Python interpreter can now infer the memory layout.\n",
    "\n",
    "**Exercise**: Check the dtype of `a`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy has some convenience methods for creating new ndarrays. As you saw above, one way to create an ndarray is to pass a list with the values to `np.array`. Here are some others...\n",
    "\n",
    "Using np.array directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.arange` will generate numbers between limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.linspace is extremely useful, you tell it where to start and stop and how many samples you need and linspace does the rest. Here we will create numbers 100 numbers between 0 (inclusive) and 1, linearly spaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.zeros` function will generate an `ndarray` full of zeros. You can pass the `dtype=` argument to tell it what type of number you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1 100 integer zeros\n",
    "\n",
    "# z2 a 5,5 array of float64 zeros\n",
    "z1 = np.zeros(100, dtype='int64')\n",
    "z1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.ones` function does something similar, but with unit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1 100 integers ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o2 a 5x5 ndarray of complex128 one values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.eye` function genrates a 2D array with ones down the diagonal, zeros elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1 a 5x5 array with ones down the diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to the `numpy.random` module later on, but it has some useful convenience methods. `np.random.randint` returns random integers. Take a look at the help on the method then create a name `r1` with an array of `4x5` random numbers between `0` and `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1 a 4x5 array of random integers between 0 & 10, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Now that we have some `ndarray`s to play with, lets look at using them. Of course, `ndarray`s are zero indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First element of a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual negative number notation works for couting from the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd to last element of a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing returns subarrays of the original `ndarray`. Crucially it does this inexpensively by returning a \"view\" on the data rather than copying it. This is much more efficient and relies on numpy is using it's knowledge of the memory layout to return only the things you ask for. This is a general tactic used by numpy, if it _can_ return a view rather than a copy it _will_! \n",
    "\n",
    "Slicing uses the same notation as core python: `[start:stop:step]` where `start` is inclusive and `stop` is exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values between 3 and 19 of a2\n",
    "\n",
    "# Every third value between 3 and 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using negative is allowed for all three parts of the slice, but for the step you have to think a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values between -10 and -2\n",
    "\n",
    "# Values between 10 and 0, reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-dimensional arrays the indexing notation is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(100)\n",
    "b.shape = (10, 10)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the slice notation in either dimension (You can also use higher dimensions etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Arrays\n",
    "\n",
    "Sometimes it is convenient to reshape arrays. I did this above by setting the `.shape` attribute. `ndarray`s also have a reshape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.arange(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create d with shape (3, 9\n",
    "\n",
    "# Check if `d.base` is `c`\n",
    "\n",
    "# Reshape d to be (3,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common reshaping task is to add dimension(s) to an existing array. numpy has a special `newaxis` object for this task. This is a powerful idea when combined with numpy's broadcasting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.arange(10)\n",
    "\n",
    "# Add new axes before and after the existing one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Operations\n",
    "\n",
    "The real reason for using numpy is so you can do numerical operation, _quickly_. Python uses a concenpt called `ufuncs` for universal function. A ufunc is a function which operates on `ndarrays` element-by-element. In more familiar language a ufunc is a vectorized wrapper around a function which can do a transformation on an `ndarray` and produces another `ndarray`.\n",
    "\n",
    "The key to writing fast numeric python code is: **Avoid for & while loops as far as you can, use numpy ufuncs as far as possible**\n",
    "\n",
    "\n",
    "Lets start with basic arithmetic operations. Numpy can use it's internal broadcasting to do these quickly and efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual operations are available\n",
    "\n",
    "  * +: addition\n",
    "  * -: subtraction\n",
    "  * *: multiplication\n",
    "  * /: division\n",
    "  * //: integer division\n",
    "  * **: power operator\n",
    "  * %: modulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are element by element, and you can build up more complicated expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = np.linspace(0, 1, 100)\n",
    "\n",
    "# Do some element-by-element arithmetic with la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Try to calculate the terms of this sum as an `ndarray`\n",
    "$$\n",
    "\\sqrt{12}\\sum_{k=0}^{10}\\frac{(-3)^{-k}}{2k+1}\n",
    "$$\n",
    "\n",
    "_Hints_: Think term by term. `np.arange(10)` will give you an `ndarray` the array of k values, next raise `-3. * np.ones(10)` to those powers. If you can calculate the terms you can use the `.sum()` method to sum them all up. How close to $\\pi$ did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operators we were using `+,-,/,...` actually correspond to functions\n",
    "\n",
    "|operator|function|description|\n",
    "|--------|--------|-----------|\n",
    "| + | np.add | Addition |\n",
    "| - | np.subtract | Subtraction |\n",
    "| - | np.negative | Unary negation |\n",
    "| * | np.multiply | Multiplication |\n",
    "| / | np.division | Ordinary floating point division |\n",
    "| // | np.floor_divide | floor (integer) division |\n",
    "| % | np.mod | Modulo/Remainder division |\n",
    "\n",
    "You can use either syntax, but in the function notation there are lots more functions to play with e.g.\n",
    "\n",
    "| function | description |\n",
    "|----------|-------------|\n",
    "| np.sin   | sin function |\n",
    "| np.cos   | cos function |\n",
    "| np.tan   | tan function |\n",
    "| np.abs   | absolute value |\n",
    "| np.exp   | exponential |\n",
    "| np.log   | natural log |\n",
    "| np.log2  | log base 2 |\n",
    "| np.log10 | log base 10 |\n",
    "|  ...     |    ...      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.linspace(0, 2*np.pi, 25)\n",
    "\n",
    "# p2 sin of p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.linspace(0, 1, 10) + np.linspace(1, 2, 10)*1j\n",
    "\n",
    "# Show `.abs` value of q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions\n",
    "\n",
    "Aggregate functions take an `ndarray` and reduce it along one (or more axes). An example would be taking an array of numbers and calculating the mean value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(0, 10, 100)\n",
    "\n",
    "# Find the `.mean` value of r1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also aggregate functions for `min`, `max`, `median` etc. In more than one dimension you can specify how you which axes you would like to take the aggregate value along\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.arange(50)\n",
    "s2 = s1.reshape(5,10)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of s2\n",
    "\n",
    "# The mean of s2 along the 0 axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary operations (e.g. addition) you can also do reduction, so starting from\n",
    "\n",
    "[1, 3, 5, 7, 9]\n",
    "\n",
    "`np.add.reduce` will add 1 to 3, add that to 5 and so on,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.arange(1, 10, 2)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `.add` and `.reduce` t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with Booleans and \"fancy\" indexing\n",
    "\n",
    "numpy has some more advanced tricks up it's sleve when indexing. If we do a boolean test on an `ndarray` the result will be the same shape as the `ndarray` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.linspace(0, 1, 100)\n",
    "\n",
    "# Where is u1 less than 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy will let us use this to index arrays of the same shape (see also `np.where`)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the values of u1 which are less than 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do other things with the boolean values like `.count_nonzero` them, checking if `.all` values or `.any` values are true etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing\n",
    "\n",
    "Fancy is the idea of using another array of indices, it is useful when the combinations you want to select become a bit more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.arange(27)[::-1]\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1[[1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v1.reshape(3,9)\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2[[1, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "broadcasting is widely used in numpy, but thankfully you don't have to think too much about it. That said, it is useful to understand the basic ideas. Basically numpy wants to operate element-by-element, but sometimes `ndarray` shapes won't quite match up. As an example, think of\n",
    "```\n",
    "np.arange(10) * 5\n",
    "```\n",
    "numpy wants to operate element-by-element, but `5` isn't an `ndarray`. To make things work element-by-element we could think of `5` as being replaced by `np.ones(5)`, i.e. make an `ndarray` the same shape as `np.arange(10)` and fill it with copies of `5`. This is the basic idea of broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
